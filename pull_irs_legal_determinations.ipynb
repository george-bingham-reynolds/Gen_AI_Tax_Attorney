{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fec1b3-8502-4dc9-9df0-bca5d9a51ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RESTART KERNEL AFTER INSTALLING\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e020dc9b-6225-4823-a290-73b27ac48266",
   "metadata": {},
   "source": [
    "PULL INFO FOR ALL IRS WRITTEN DETERMINATIONS TO FORM OUR DATABASE\n",
    "\n",
    "NOTE THAT SCRAPING CODE WAS GENERATED BY GPT API, EDITED BY ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598b8cb-36e6-47cc-a647-391fadbbc6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMPORT NECESSARY PACKAGES\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d6cd7-cfc5-4162-a1e7-96708249fe50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEFINE VARIABLES FOR GOOGLE CLOUD INTEGRATION \n",
    "REGION = 'us-central1' # NEEDS TO BE SAME REGION AS BUCKETS, OTHER NBs, INSTANCE, ETC.\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "BUCKET = 'gs://legal_precedents_test' # REPLACE WITH YOUR OWN BUCKET NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aad404-3607-4d90-93af-deffbf1cd5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEFINE FUNCTION TO SCRAPE THE TABLE ON THE IRS WEBPAGE, GET CORE INFO ON CASES\n",
    "def scrape_table(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'tablesaw tablesaw-stack table table-hover table-striped pup-table'})\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cells = row.find_all('td')\n",
    "        number = cells[0].find('a').text.strip()\n",
    "        uilc = cells[1].text.strip()\n",
    "        subject = cells[2].text.strip()\n",
    "        release_date = cells[3].text.strip()\n",
    "        pdf_url = cells[0].find('a')['href']\n",
    "        data.append([number, uilc, subject, release_date, pdf_url])\n",
    "    \n",
    "    return data, soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd45a12-a748-4caa-8e06-7518c5ee268a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCRAPE THE FIRST PAGE\n",
    "url = 'https://www.irs.gov/written-determinations'\n",
    "first_time = scrape_table(url)\n",
    "data = first_time[0]\n",
    "soup = first_time[1]\n",
    "\n",
    "# AND SUBSEQUENT PAGES IF AVAILABLE \n",
    "next_page = soup.find('li', {'class': 'pager__item pager__item--next'})\n",
    "\n",
    "while next_page:\n",
    "    next_url = url + next_page.find('a').get('href','') if next_page.find('a') else ''\n",
    "    instance = scrape_table(next_url)\n",
    "    new_data = instance[0]\n",
    "    new_soup = instance[1]\n",
    "    data += new_data\n",
    "    next_page = new_soup.find('li', {'class': 'pager__item pager__item--next'})\n",
    "\n",
    "# CONVERT TO PANDAS DATAFRAME\n",
    "df = pd.DataFrame(data, columns=['Number', 'UILC', 'Subject', 'Release Date', 'pdf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f17711-096a-4bcb-b6ab-b6f9ab34b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK DF\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cfca9f-c991-48ce-b9f5-1466c0afa3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND SAVE LOCAL CSV\n",
    "df.to_csv(\"scraped_determinations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ff56c-25a6-441b-8571-6e269a762b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREATE BUCKET IF YOU HAVEN'T ALREADY\n",
    "!gsutil mb -l {REGION} {BUCKET} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102ff2e-7241-4ed1-a6d9-0a60beac4251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SAVE CSV IN CLOUD STORAGE TO MAKE SURE YOU HAVE IT MOVING FORWARD\n",
    "!gsutil cp scraped_determinations.csv {BUCKET}/scraped_determinations.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df652e-fddc-4a26-a8bb-a497b5f25d7d",
   "metadata": {},
   "source": [
    "SAVE PDF OF ALL WDs FOR VECTOR SEARCH IN LATER NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584af3f3-9eb5-405c-9ac1-1bea3ea782bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189591b1-d778-4ec8-8e0d-7634ec92ef93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOT ALL PDFs PULLED ARE USEABLE - WANT TO TOSS THE CORRUPTED ONES\n",
    "def checkFile(fullfile):\n",
    "    with open(fullfile, 'rb') as f:\n",
    "        try:\n",
    "            pdf = PdfReader(f)\n",
    "            info = pdf.metadata\n",
    "            if info:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7568d-833a-4552-ad17-11e0bed28049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # IF YOU NEED TO RESTART KERNEL READ-IN LOCAL FILE INSTEAD OF RE-RUNNING SCRAPE\n",
    "# df = pd.read_csv(\"scraped_determinations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331dc379-b5eb-41ff-886c-524243faae81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE THAT WE ARE WORKING WITH A NEW BUCKET\n",
    "BUCKET = 'gs://irs_written_determinations_test/' # CHANGE TO YOUR OWN NAMING CONVENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae753f-71ce-4fd7-8c45-c13b43257263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREATE BUCKET FOR PDF STORAGE\n",
    "!gsutil mb -l {REGION} {BUCKET} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55cfae-0338-48da-ba8f-cfc34df7c79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USE URL TO GET LOCAL COPY OF PDF OF WRITINGS ON THE ACTUAL CASE\n",
    "# NOTE THAT INITIAL SCRAPE PULLED THE NAME OF THE PDF THAT THE WEBSITE LINKS TO FOR THOSE WANTING TO SEE WRITING\n",
    "counter = 1\n",
    "for pdf in list(set(df['pdf'].values.tolist())):\n",
    "    print(counter) #YOU CAN DELETE THIS PART - I PERSONALLY LIKE IT TO KEEP TRACK OF PROGRESS\n",
    "    url = \"https://www.irs.gov\" + pdf\n",
    "    \n",
    "    local_file_path = pdf[12:]\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    with open(local_file_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    # ONLY ADDING USEABLE FILES TO OUR BUCKET FOR SEMANTIC SEARCH LATER\n",
    "    if checkFile(local_file_path):\n",
    "        os.system(f\"gsutil cp {local_file_path} {BUCKET}\")\n",
    "        os.system(f\"rm {local_file_path}\")\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033915b9-c3ed-41fb-95f3-f5b98ac1f0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CHECK HOW MANY FILES ARE IN THE BUCKET; \n",
    "# I'VE TYPICALLY SEEN ON THE ORDER OF 40-50K, BUT THE NUMBER WILL INCREASE OVER TIME\n",
    "# NOTE THAT SOMETIMES YOU HAVE TO RESTART INSTANCE TO RUN THIS PART\n",
    "# BECAUSE NB SEEMS TO BE STUCK HANGING, BUT PDFS HAVE ACTUALLY BEEN UPLOADED\n",
    "!gsutil du {BUCKET} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f99abf-a506-44b4-934d-682db7f230c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
